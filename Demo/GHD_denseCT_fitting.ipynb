{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "pv.start_xvfb(wait=0)\n",
    "pv.set_jupyter_backend('html')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join('..', '.'))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.io import load_objs_as_meshes, save_obj\n",
    "from pytorch3d.ops import cubify, cot_laplacian, sample_points_from_meshes, knn_points, knn_gather, norm_laplacian, taubin_smoothing\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from pytorch3d.utils import ico_sphere\n",
    "\n",
    "from torch_geometric.utils import degree, to_undirected, to_dense_adj, get_laplacian, add_self_loops\n",
    "from torch_geometric.data import Data\n",
    "# from torch_geometric.transforms import gdc\n",
    "from torch_scatter import scatter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import trimesh\n",
    "\n",
    "\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "\n",
    "from data_process.dataset_real_scaling import UKBB_dataset, MMWHS_dataset, ACDC_dataset, CCT48_dataset\n",
    "from ops.graph_operators import NativeFeaturePropagation, LaplacianSmoothing\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from probreg import cpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from pytorch3d.transforms import axis_angle_to_matrix, matrix_to_axis_angle\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from GHD import GHD_config, GHDmesh, Normal_iterative_GHDmesh\n",
    "from GHD.GHD_cardiac import GHD_Cardiac\n",
    "\n",
    "\n",
    "from data_process.dataset_real_scaling import UKBB_dataset, MMWHS_dataset, ACDC_dataset, CCT48_dataset\n",
    "\n",
    "from einops import rearrange, einsum, repeat\n",
    "\n",
    "from pytorch3d.loss import chamfer_distance,mesh_laplacian_smoothing, mesh_normal_consistency, mesh_edge_loss\n",
    "\n",
    "\n",
    "from losses import *\n",
    "from ops.mesh_geometry import *\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_shape_path = '../canonical_shapes/Standard_LV_2000.obj'\n",
    "bi_ventricle_path = '../canonical_shapes/Standard_BiV.obj'\n",
    "\n",
    "# base_shape_path = 'metadata/Standard_LV.obj'\n",
    "# bi_ventricle_path = 'metadata/Standard_BiV.obj'\n",
    "\n",
    "cfg = GHD_config(base_shape_path=base_shape_path,\n",
    "            num_basis=7**2, mix_laplacian_tradeoff={'cotlap':1.0, 'dislap':0.1, 'stdlap':0.1},\n",
    "            device='cuda:3',\n",
    "            if_nomalize=True, if_return_scipy=True, \n",
    "            bi_ventricle_path=bi_ventricle_path)\n",
    "\n",
    "paraheart = GHD_Cardiac(cfg) # \n",
    "\n",
    "\n",
    "# load initial orientation according to dataset\n",
    "\n",
    "with open('../canonical_shapes/mmwhs_init_affine.pkl', 'rb') as f:\n",
    "    initial_orientation = pickle.load(f)\n",
    "\n",
    "R = initial_orientation[:3,:3].astype(np.float32)\n",
    "T = initial_orientation[:3,3].astype(np.float32)\n",
    "\n",
    "paraheart.R = matrix_to_axis_angle(torch.from_numpy(R).to(paraheart.device)).view(paraheart.R.shape)\n",
    "paraheart.T = torch.from_numpy(T).to(paraheart.device).view(paraheart.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.dirname(os.path.realpath('..'))\n",
    "\n",
    "root_path = os.path.join(root_path,'Dataset','MMWHS')\n",
    "\n",
    "mmwhs_bi_lv = MMWHS_dataset(output_size=(128, 128, 128),dataset_path=root_path,\n",
    "                            if_augment=False, label_value_list=[[205.,600.],[205.]],eps= 0.01, process_device=paraheart.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_mmwhs = DataLoader(mmwhs_bi_lv, batch_size=1, shuffle=False)\n",
    "\n",
    "LaplacianSmoother = LaplacianSmoothing()\n",
    "\n",
    "for i, data in enumerate(dataloader_mmwhs):\n",
    "    if i<1:\n",
    "        continue\n",
    "    # if i not in [15]:\n",
    "    #     continue\n",
    "    # img = data['img'].to(device)\n",
    "    seg_gt = data['seg_gt']\n",
    "\n",
    "    seg_gt_bi = seg_gt[:,0,...].to(paraheart.device).float()\n",
    "    seg_gt_lv = seg_gt[:,1,...].to(paraheart.device).float()\n",
    "\n",
    "\n",
    "    window_size = data['window_size'].to(paraheart.device).float()\n",
    "\n",
    "    mesh_gt_lv = cubify(seg_gt_lv, 0.5)\n",
    "    mesh_gt_lv = mesh_gt_lv.update_padded((mesh_gt_lv.verts_padded()*window_size/200).float())\n",
    "    # mesh_gt_lv = LaplacianSmoother.mesh_smooth(mesh_gt_lv, num_iterations=1)\n",
    "    mesh_gt_lv = taubin_smoothing(mesh_gt_lv, 0.1, 0.5, num_iter=20)\n",
    "    \n",
    "\n",
    "\n",
    "    mesh_gt_bi = cubify(seg_gt_bi, 0.5)\n",
    "    mesh_gt_bi = mesh_gt_bi.update_padded((mesh_gt_bi.verts_padded()*window_size/200).float())\n",
    "    # mesh_gt_bi = LaplacianSmoother.mesh_smooth(mesh_gt_bi, num_iterations=1)\n",
    "    mesh_gt_bi = taubin_smoothing(mesh_gt_bi, 0.1, 0.5, num_iter=20)\n",
    "\n",
    "    bbox_lv = mesh_gt_lv.get_bounding_boxes()[0]*1.3\n",
    "    # point cloud from the mask\n",
    "    # bi-ventricle\n",
    "    points_bi = torch.stack(torch.where(seg_gt_bi>0.5)[1:], dim=-1).float()\n",
    "    points_bi = points_bi/(torch.tensor(seg_gt_bi.shape[-3:]).float().to(paraheart.device)-1)*2-1\n",
    "    points_bi = points_bi[:,[2,1,0]]*window_size/200\n",
    "\n",
    "    # left ventricle\n",
    "    points_lv = torch.stack(torch.where(seg_gt_lv>0.5)[1:], dim=-1).float()\n",
    "    points_lv = points_lv/(torch.tensor(seg_gt_lv.shape[-3:]).float().to(paraheart.device)-1)*2-1\n",
    "    points_lv = points_lv[:,[2,1,0]]*window_size/200 \n",
    "\n",
    "    # out of the LV\n",
    "    points_outoflv = torch.stack(torch.where(seg_gt_lv<0.5)[1:], dim=-1).float()\n",
    "    points_outoflv = points_outoflv/(torch.tensor(seg_gt_lv.shape[-3:]).float().to(paraheart.device)-1)*2-1\n",
    "    points_outoflv = points_outoflv[:,[2,1,0]]*window_size/200\n",
    "\n",
    "    points_outoflv_in_bbox = points_outoflv[(points_outoflv[:,0]>bbox_lv[0,0]) & (points_outoflv[:,0]<bbox_lv[0,1]) & (points_outoflv[:,1]>bbox_lv[1,0]) & (points_outoflv[:,1]<bbox_lv[1,1]) & (points_outoflv[:,2]>bbox_lv[2,0]) & (points_outoflv[:,2]<bbox_lv[2,1])]\n",
    "\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 2000\n",
    "\n",
    "mesh_gt_bi_sample = points_bi.detach().cpu().numpy()[np.random.choice(points_bi.shape[0], sample_num, replace=False)]\n",
    "paraheart.global_registration_biv(mesh_gt_bi_sample)\n",
    "\n",
    "\n",
    "sample_lv = points_lv[np.random.choice(points_lv.shape[0], sample_num, replace=False)]\n",
    "paraheart.global_registration_lv(sample_lv.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pv.Plotter(notebook=True)\n",
    "trimesh_gt_lv = trimesh.Trimesh(mesh_gt_lv.verts_packed().detach().cpu().numpy(), mesh_gt_lv.faces_packed().detach().cpu().numpy())\n",
    "trimesh_gt_lv = pv.wrap(trimesh_gt_lv)\n",
    "pl.add_mesh(trimesh_gt_lv, color='lightgreen', opacity=0.5)\n",
    "\n",
    "# trimesh_gt_bi = trimesh.Trimesh(mesh_gt_bi.verts_packed().detach().cpu().numpy(), mesh_gt_bi.faces_packed().detach().cpu().numpy())\n",
    "# trimesh_gt_bi = pv.wrap(trimesh_gt_bi)\n",
    "# pl.add_mesh(trimesh_gt_bi, color='green', opacity=0.2)\n",
    "\n",
    "\n",
    "out_ghd_mesh = paraheart.rendering()\n",
    "\n",
    "# trimesh_current_bi = paraheart.rendering_bi_ventricle()\n",
    "# trimesh_current_bi = pv.wrap(trimesh_current_bi)\n",
    "# pl.add_mesh(trimesh_current_bi, color='blue', opacity=0.2)\n",
    "\n",
    "\n",
    "trimesh_current_lv = trimesh.Trimesh(out_ghd_mesh.verts_packed().detach().cpu().numpy(), out_ghd_mesh.faces_packed().detach().cpu().numpy())\n",
    "trimesh_current_lv = pv.wrap(trimesh_current_lv)\n",
    "pl.add_mesh(trimesh_current_lv, color='lightblue', opacity=0.5)\n",
    "\n",
    "# pl.add_points(points_bi.detach().cpu().numpy(), color='red', point_size=5)\n",
    "pl.add_points(points_lv.detach().cpu().numpy(), color='yellow', point_size=5)\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sample_outoflv = points_outoflv_in_bbox[np.random.choice(points_outoflv_in_bbox.shape[0], sample_num*5, replace=False)]\n",
    "\n",
    "convergence, Loss_dict_list  = paraheart.morphing2lvtarget(points_lv, points_outoflv_in_bbox, target_mesh=mesh_gt_lv, loss_dict \n",
    "                            = {'Loss_occupancy':1, 'Loss_normal_consistency':0.01, 'Loss_Laplacian':0.02, 'Loss_equaledge':0.01, 'Loss_rigid':0.1}, \n",
    "                            lr_start=1e-4, num_iter=2000, if_reset=True, if_fit_R=False, if_fit_s=True, if_fit_T=True, record_convergence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pv.Plotter(notebook=True)\n",
    "\n",
    "out_ghd_mesh = paraheart.rendering()\n",
    "\n",
    "trimesh_current_lv = trimesh.Trimesh(out_ghd_mesh.verts_packed().detach().cpu().numpy(), out_ghd_mesh.faces_packed().detach().cpu().numpy())\n",
    "trimesh_current_lv = pv.wrap(trimesh_current_lv)\n",
    "\n",
    "pl.add_mesh(trimesh_current_lv, color='lightblue', opacity=0.5)\n",
    "pl.add_points(points_lv.detach().cpu().numpy(), color='yellow', point_size=5)\n",
    "pl.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MedicalImage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
